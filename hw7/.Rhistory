install.packages('tm')
#library(tm)
# news<-read.csv("news.csv",header=T)
yes
install.packages('tm', dependencies = TRUE)
#library(tm)
# news<-read.csv("news.csv",header=T)
install.packages("tm")
setwd("/Users/phuong/Desktop/Data 180 Phuong Hoang/Phuong-Hoang---Data-180/hw7")
# Custom options for knitting
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
error = FALSE,
fig.align = "center",
cache = FALSE
)
# install.packages('tm', dependencies = TRUE)
library(tidyverse)
posWords <- scan("positive-words.txt", character(0), sep = "\n")  # 2006 items
negWords <- scan("negative-words.txt", character(0), sep = "\n")  # 4783 items
head(posWords,15)
head(negWords,15)
# Extract unique years from the third column
unique_years <- unique(as.integer(format(as.Date(news[, 3]), "%Y")))
posWords <- scan("positive-words.txt", character(0), sep = "\n")  # 2006 items
negWords <- scan("negative-words.txt", character(0), sep = "\n")  # 4783 items
head(posWords,15)
head(negWords,15)
# Extract unique years from the third column
unique_years <- unique(as.integer(format(as.Date(news[, 3]), "%Y")))
library(quanteda)
# Assuming 'news_dtm' is the term-document matrix
# Run LDA with k = 8 topics
topic_model <- textmodel_lda(news_dtm, k = 8)
range <- range(news$year)
library(tidyverse)
library(tm)
news<-read.csv("/Users/phuong/Desktop/Data 180 Phuong Hoang/Phuong-Hoang---Data-180/hw7",header=T)
setwd("/Users/phuong/Desktop/Data 180 Phuong Hoang/Phuong-Hoang---Data-180/hw7")
library(tidyverse)
library(tm)
news<-read.csv("/Users/phuong/Desktop/Data 180 Phuong Hoang/Phuong-Hoang---Data-180/hw7",header=T)
setwd("/Users/phuong/Desktop/Data 180 Phuong Hoang/Phuong-Hoang---Data-180/hw7")
# Custom options for knitting
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
error = FALSE,
fig.align = "center",
cache = FALSE
)
posWords <- scan(setwd("/Users/phuong/Desktop/Data 180 Phuong Hoang/Phuong-Hoang---Data-180/hw7"), character(0), sep = "\n")  # 2006 items
topic_model <- LDA(news_topics, method = "VEM", k = 8)
setwd("/Users/phuong/Desktop/Data 180 Phuong Hoang/Phuong-Hoang---Data-180/hw7")
# Custom options for knitting
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
error = FALSE,
fig.align = "center",
cache = FALSE
)
# install.packages('tm', dependencies = TRUE)
library(tidyverse)
library(tm)
news<-read.csv("news.csv",header=T)
posWords <- scan("positive-words.txt", character(0), sep = "\n")  # 2006 items
negWords <- scan("negative-words.txt", character(0), sep = "\n")  # 4783 items
head(posWords,15)
head(negWords,15)
range <- range(news$year)
year_range = range[2] - range[1]
year_range
charVector <- news$headline_text
head(charVector)
charVector
charVector <- news$headline_text
head(charVector)
charVector[ :6]
charVector <- news$headline_text
head(charVector)
print(charVector[1:6])
charVector <- news$headline_text
head(charVector)
print(charVector[1:6])
charVector <- news$headline_text
print(head(charVector)[1:6])
#print(charVector[1:6])
charVector <- news$headline_text
print(head(charVector[1:6]))
#print(charVector[1:6])
wordVector <- VectorSource(charVector)
wordCorpus <- Corpus(wordVector)
#wordCorpus
wordVector <- VectorSource(charVector)
wordCorpus <- Corpus(wordVector)
charVector <- news$headline_text
head(charVector)
print(charVector[1:6])
library(tm)
library(SnowballC)  # Required for some text processing functions
tm_map(wordCorpus, tolower)
tm_map(wordCorpus, removeNumbers)
tm_map(wordCorpus, removePunctuation)
tm_map(wordCorpus, removeWords, stopwords("english"))
barplot(wordCounts[wordFrequency >= 50], las = 2, cex.names = 0.75, angle = 90)
library(tm)
library(SnowballC)  # Required for some text processing functions
tm_map(wordCorpus, tolower)
tm_map(wordCorpus, removeNumbers)
tm_map(wordCorpus, removePunctuation)
tm_map(wordCorpus, removeWords, stopwords("english"))
tdm <- TermDocumentMatrix(wordCorpus)
m <- as.matrix(tdm)
dim(m)
wordCounts <- rowSums(m)
wordFrequency <- sort(wordCounts, decreasing = TRUE)
topWords <- head(wordFrequency, 10)
topWords
barplot(wordCounts[wordFrequency >= 50], las = 2, cex.names = 0.75, angle = 90)
